{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = './twitter_data/train2017.tsv'\n",
    "df = pd.read_csv(location , sep=\"\\t\" , header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gas', 'by', 'my', 'house', 'hit', '.', '39', '!', '!', '!', \"i'm\", 'going', 'to', 'chapel', 'hill', 'on', 'sat', '.', ':)']\n",
      "['theo', 'walcott', 'is', 'still', 'shit', ',', 'watch', 'rafa', 'and', 'johnny', 'deal', 'with', 'him', 'on', 'saturday', '.']\n",
      "['its', 'not', 'that', \"i'm\", 'a', 'gsp', 'fan', ',', 'i', 'just', 'hate', 'nick', 'diaz', '.', \"can't\", 'wait', 'for', 'february', '.']\n",
      "['iranian', 'general', 'says', \"israel's\", 'iron', 'dome', \"can't\", 'deal', 'with', 'their', 'missiles', '(', 'keep', 'talking', 'like', 'that', 'and', 'we', 'may', 'end', 'up', 'finding', 'out', ')']\n",
      "['tehran', ',', 'mon', 'amour', ':', 'obama', 'tried', 'to', 'establish', 'ties', 'with', 'the', 'mullahs']\n",
      "['i', 'sat', 'through', 'this', 'whole', 'movie', 'just', 'for', 'harry', 'and', 'ron', 'at', 'christmas', '.', 'ohlawd']\n",
      "['with', 'j', 'davlar', '11th', '.', 'main', 'rivals', 'are', 'team', 'poland', '.', 'hopefully', 'we', 'an', 'make', 'it', 'a', 'successful', 'end', 'to', 'a', 'tough', 'week', 'of', 'training', 'tomorrow', '.']\n",
      "['talking', 'about', \"act's\", '&', '&', \"sat's\", ',', 'deciding', 'where', 'i', 'want', 'to', 'go', 'to', 'college', ',', 'applying', 'to', 'colleges', 'and', 'everything', 'about', 'college', 'stresses', 'me', 'out', '.']\n",
      "['why', 'is', '\\\\', '\"', '\"', 'happy', 'valentines', 'day', '\\\\', '\"', '\"', 'trending', '?', \"it's\", 'on', 'the', '14th', 'of', 'february', 'not', '12th', 'of', 'june', 'smh', '..']\n",
      "['they', 'may', 'have', 'a', 'superbowl', 'in', 'dallas', ',', 'but', 'dallas', \"ain't\", 'winning', 'a', 'superbowl', '.', 'not', 'with', 'that', 'quarterback', 'and', 'owner', '.']\n",
      "\n",
      "\n",
      "[['gas', 'house', 'hit', 'going', 'chapel', 'hill', 'sat'], ['theo', 'walcott', 'still', 'shit', 'watch', 'rafa', 'johnny', 'deal', 'saturday'], ['gsp', 'fan', 'hate', 'nick', 'diaz', 'cant', 'wait', 'february'], ['iranian', 'general', 'says', 'israels', 'iron', 'dome', 'cant', 'deal', 'missiles', 'keep', 'talking', 'like', 'may', 'end', 'finding'], ['tehran', 'mon', 'amour', 'obama', 'tried', 'establish', 'ties', 'mullahs'], ['sat', 'whole', 'movie', 'harry', 'ron', 'christmas', 'ohlawd'], ['j', 'davlar', 'main', 'rivals', 'team', 'poland', 'hopefully', 'make', 'successful', 'end', 'tough', 'week', 'training', 'tomorrow'], ['talking', 'acts', 'sats', 'deciding', 'want', 'go', 'college', 'applying', 'colleges', 'everything', 'college', 'stresses'], ['happy', 'valentines', 'day', 'trending', 'february', 'june', 'smh'], ['may', 'superbowl', 'dallas', 'dallas', 'aint', 'winning', 'superbowl', 'quarterback', 'owner']]\n",
      "\n",
      "\n",
      "['gas', 'house', 'hit', 'going', 'chapel', 'hill', 'sat', 'theo', 'walcott', 'still', 'shit', 'watch', 'rafa', 'johnny', 'deal', 'saturday', 'gsp', 'fan', 'hate', 'nick', 'diaz', 'cant', 'wait', 'february', 'iranian', 'general', 'says', 'israels', 'iron', 'dome', 'cant', 'deal', 'missiles', 'keep', 'talking', 'like', 'may', 'end', 'finding', 'tehran', 'mon', 'amour', 'obama', 'tried', 'establish', 'ties', 'mullahs', 'sat', 'whole', 'movie', 'harry', 'ron', 'christmas', 'ohlawd', 'j', 'davlar', 'main', 'rivals', 'team', 'poland', 'hopefully', 'make', 'successful', 'end', 'tough', 'week', 'training', 'tomorrow', 'talking', 'acts', 'sats', 'deciding', 'want', 'go', 'college', 'applying', 'colleges', 'everything', 'college', 'stresses', 'happy', 'valentines', 'day', 'trending', 'february', 'june', 'smh', 'may', 'superbowl', 'dallas', 'dallas', 'aint', 'winning', 'superbowl', 'quarterback', 'owner']\n"
     ]
    }
   ],
   "source": [
    "ndf = df.head(10) #takes the first x entries\n",
    "\n",
    "dl = ndf.values.tolist()\n",
    "tknzr = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "tokens = []\n",
    "fusedTokens = []\n",
    "positives = []\n",
    "negatives = []\n",
    "neutrals = []\n",
    "\n",
    "for item in dl:\n",
    "    \n",
    "    tweet = item[3]\n",
    "    \n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    " \n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    " \n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    \n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    \n",
    "    temp = tknzr.tokenize(tweet)\n",
    "    \n",
    "    print(temp)\n",
    "    \n",
    "#     temp = [w.lower() for w in temp] #convert to lower case\n",
    "    \n",
    "    stop_words = stopwords.words('english')    #sets stop words\n",
    "    newStopWords = [\"i'm\" , \"he's\" , \"she's\" , \"we're\" , \"you're\" , \"they're\"]\n",
    "    stop_words.extend(newStopWords)\n",
    "    stop_words = set(stop_words)\n",
    "    \n",
    "    temp = [w for w in temp if not w in stop_words]  #removes stop words\n",
    "    \n",
    "    table = str.maketrans('', '', string.punctuation) #remove punctuation\n",
    "    temp = [w.translate(table) for w in temp]\n",
    "    \n",
    "    temp = [word for word in temp if word.isalpha()] #remove remaining tokens that are not alphabetic\n",
    "    \n",
    "#     porter = PorterStemmer() #stemming (not that useful)\n",
    "#     temp = [porter.stem(word) for word in temp]\n",
    "\n",
    "    if item[2] == \"positive\":  #need to give the words positive and negative weight so that the most common words in positive posts is not \"tomorrow\"\n",
    "        positives.extend(temp)\n",
    "    elif item[2] == \"negative\":\n",
    "        negatives.extend(temp);\n",
    "    elif item[2] == \"neutral\":\n",
    "        neutrals.extend(temp)\n",
    "        \n",
    "    fusedTokens.extend(temp)\n",
    "    tokens.append(temp)\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(tokens)\n",
    "print(\"\\n\")\n",
    "print(fusedTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generally most common words :  [('sat', 2), ('deal', 2), ('cant', 2), ('february', 2), ('talking', 2), ('may', 2), ('end', 2), ('college', 2), ('superbowl', 2), ('dallas', 2)]\n",
      "Most common words found in positive posts :  [('gas', 1), ('house', 1), ('hit', 1), ('going', 1), ('chapel', 1), ('hill', 1), ('sat', 1), ('j', 1), ('davlar', 1), ('main', 1)]\n",
      "Most common words found in negative posts :  [('deal', 2), ('cant', 2), ('talking', 2), ('may', 2), ('college', 2), ('superbowl', 2), ('dallas', 2), ('theo', 1), ('walcott', 1), ('still', 1)]\n",
      "Most common words found in neutral posts :  [('tehran', 1), ('mon', 1), ('amour', 1), ('obama', 1), ('tried', 1), ('establish', 1), ('ties', 1), ('mullahs', 1), ('sat', 1), ('whole', 1)]\n"
     ]
    }
   ],
   "source": [
    "count = Counter(fusedTokens)\n",
    "print(\"Generally most common words : \" , count.most_common(10))\n",
    "\n",
    "count = Counter(positives)\n",
    "print(\"Most common words found in positive posts : \" , count.most_common(10))\n",
    "\n",
    "count = Counter(negatives)\n",
    "print(\"Most common words found in negative posts : \" , count.most_common(10))\n",
    "\n",
    "count = Counter(neutrals)\n",
    "print(\"Most common words found in neutral posts : \" , count.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
